import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ì•½ì–´	ì´ë¦„	                 ì „ì²´ ì´ë¦„	                      ì¢…ë¥˜	        ì£¼ìš” ì—­í• 
# NR	ì²œì—°ê³ ë¬´	             Natural Rubber	                  ì²œì—°	        íƒ„ì„±, ê°•ë„, ë³µì›ë ¥
# SBR	ìŠ¤í‹°ë Œ-ë¶€íƒ€ë””ì—” ê³ ë¬´     Styrene-Butadiene Rubber	      í•©ì„±	        ë‚´ë§ˆëª¨ì„±, ì –ì€ ë…¸ë©´ ì ‘ì§€ë ¥
# BR	ë¶€íƒ€ë””ì—” ê³ ë¬´	         Butadiene Rubber	              í•©ì„±	        ì €ì˜¨ ìœ ì—°ì„±, íšŒì „ì €í•­ ê°ì†Œ


#1. ìœ ë¦¬ì „ì´ì˜¨ë„ (Tg, Glass Transition Temperature)
#   íƒ€ì´ì–´ì˜ íƒ„ì„±, ì ‘ì§€ë ¥, ì—°ë¹„ì— ì§ì ‘ì ì¸ ì˜í–¥
#   Tgê°€ ë‚®ìœ¼ë©´ ê²¨ìš¸ì² ì—ì„œ ìœ ì—°, ë†’ìœ¼ë©´ ê³ ì† ì£¼í–‰ ì‹œ ì„±ëŠ¥ ìœ ì§€

#2. ë°€ë„ (Density)
#   ë¬´ê²Œ, ì—°ë¹„, ì§„ë™ í¡ìˆ˜ ì„±ëŠ¥ê³¼ ì—°ê´€
#   íƒ€ì´ì–´ ì„¤ê³„ì—ì„œ êµ¬ì¡° ê°•ì„± ë° ë¬´ê²Œ ìµœì í™”ì— í•„ìš”

#3. íƒ„ì„±ë¥ ,ì˜ìœ¨ (Elastic Modulus, ë˜ëŠ” Youngâ€™s Modulus)
#   íƒ€ì´ì–´ì˜ ë³€í˜• ì €í•­ì„±, í•¸ë“¤ë§ íŠ¹ì„±
#   ë„ˆë¬´ ë‚®ìœ¼ë©´ ë³€í˜• ë§ê³ , ë„ˆë¬´ ë†’ìœ¼ë©´ ìŠ¹ì°¨ê° ì €í•˜

#4. ì†ì‹¤íƒ„ì  íŠ¸ (tan Î´ at 60Â°C ë˜ëŠ” 0Â°C)
#   60Â°Cì—ì„œì˜ tan Î´: ì—°ë¹„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
#   0Â°Cì—ì„œì˜ tan Î´: ì –ì€ ë…¸ë©´ ì ‘ì§€ë ¥ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
#   ì‹¤ì œ íƒ€ì´ì–´ ì œì¡°ì‚¬ë“¤ì´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” íŠ¹ì„± ì¤‘ í•˜ë‚˜


#5. ì¸ì¥ ê°•ë„ (Tensile Strength), ì‹ ìœ¨ (Elongation at Break)
#   íƒ€ì´ì–´ê°€ ì–¼ë§ˆë‚˜ ëŠ˜ì–´ë‚˜ê³  ì°¢ì–´ì§€ì§€ ì•ŠëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„
#   ë‚´êµ¬ì„±ê³¼ ë°€ì ‘í•œ ì—°ê´€




# íŠ¹ì„±ëª…	                        ì¤‘ìš”ë„	            	ì—°ê´€ ì„±ëŠ¥
# Tg           (ìœ ë¦¬ì „ì´ì˜¨ë„)	    â˜…â˜…â˜…â˜…â˜†	            íƒ„ì„±, ê³ ì˜¨ ì„±ëŠ¥, ì ‘ì§€ë ¥
# Density      (ë°€ë„)	        â˜…â˜…â˜…â˜†â˜†		        ë¬´ê²Œ, ì—°ë¹„, ì§„ë™
# Elasticity   (íƒ„ì„±ë¥ )	        â˜…â˜…â˜…â˜†â˜†	            í•¸ë“¤ë§, êµ¬ì¡° ê°•ì„±
# tan Î´	       (ì†ì‹¤íƒ„ì„¼íŠ¸)       â˜…â˜…â˜…â˜…â˜…	 	        ì—°ë¹„, ì ‘ì§€ë ¥
# Tensile      (ì¸ì¥ê°•ë„)	        â˜…â˜…â˜…â˜†â˜†		        ë‚´êµ¬ì„±, êµ¬ì¡°ì  ì•ˆì •ì„±



#ì¡°ì„±ì— ë”°ë¥¸ ìœ ë¦¬ì „ì´ ì˜¨ë„
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°(ë°ì´í„°ëŠ” ì‹¤ì œ ì¸¡ì •ê°’ì´ ì•„ë‹Œ ë¬¸í—Œìƒì˜ ì •ë³´ë¡œ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ ëƒˆìŠµë‹ˆë‹¤. ì‹¤ì œì™€ ë‹¤ë¥¼ìˆ˜ ìˆìŒ)
df = pd.read_csv(r".\Data\nr_sbr_br_8000_samples.csv")  # ë‹¤ìš´ë¡œë“œ ë°›ì€ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •

# ê¸°ë³¸ í™•ì¸
# print(df.head())
# print(df.describe())



from sklearn.model_selection import train_test_split

# ì…ë ¥ ë³€ìˆ˜ (ì¡°ì„±ë¹„)
X = df[['NR', 'SBR', 'BR']]

# ì˜ˆì¸¡ ëŒ€ìƒ: Tg(ìœ ë¦¬ì „ì´ ì˜¨ë„)
y = df['Tg_K']

# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ (8:2)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# print(X_train, X_test, y_train, y_test )




from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

#íšŒê·€ë¶„ì„ ëª¨ë¸ í˜¸ì¶œ
lr_model = LinearRegression()
#í•™ìŠµ , í”¼íŒ…
lr_model.fit(X_train, y_train)

#ì˜ˆì¸¡
y_pred_lr = lr_model.predict(X_test)

#ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ê°’(testì—ëŒ€í•œ) ìœ¼ë¡œ mseê³„ì‚°(ì˜¤ì°¨ì œê³±í‰ê· )
mse_lr = mean_squared_error(y_test, y_pred_lr)
#rmse ê³„ì‚°, ë£¨íŠ¸ ì”Œìš°ê¸°
rmse_lr = np.sqrt(mse_lr)

# í‰ê°€
#RÂ² (ê²°ì •ê³„ìˆ˜, Coefficient of Determination) 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì´ ë†’ë‹¤ R^2 = 1-(ì”ì°¨ì œê³±í•©/ì „ì²´ì œê³±í•©) ì”ì°¨:ì‹¤ì œê°’ - ì˜ˆì¸¡ê°’
print("ğŸ“ˆ ì„ í˜•íšŒê·€ R2:", r2_score(y_test, y_pred_lr)) #0.98ë¡œ 98% ë†’ì€ ì„¤ëª…ë¥ 
#rmse
print("ğŸ“‰ RMSE:", rmse_lr)  #1.005 1ì— ê°€ê¹Œìš°ë‹ˆ ì˜¤ì°¨ê°€ ì ìŒ






from sklearn.ensemble import RandomForestRegressor
#ëœë¤í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í˜¸ì¶œ #(ê²°ì • íŠ¸ë¦¬(Decision Tree)ì˜ ê°œìˆ˜,ë¬´ì‘ìœ„ ìš”ì†Œ ê³ ì •)
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

#ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ê°’(testì—ëŒ€í•œ) ìœ¼ë¡œ mseê³„ì‚°(ì˜¤ì°¨ì œê³±í‰ê· )
mse_rf = mean_squared_error(y_test, y_pred_rf)
#rmse ê³„ì‚°, ë£¨íŠ¸ ì”Œìš°ê¸°
rmse_rf = np.sqrt(mse_rf)

# í‰ê°€
print("ğŸ“ˆ ëœë¤í¬ë ˆìŠ¤íŠ¸ R2:", r2_score(y_test, y_pred_rf))  #0.97ë¡œ 97% ë†’ì€ ì„¤ëª…ë¥ 
print("ğŸ“‰ RMSE:", rmse_rf)  #






#6ì¸ì¹˜, 6ì¸ì¹˜ ê·¸ë˜í”„ ìƒì„±
plt.figure(figsize=(6, 6))
#ì‚°ì ë„ ì˜ˆì¸¡ y_test ì™€ ëœë¤í¬ë ˆìŠ¤íŠ¸ ì˜ˆì¸¡ê°’ ì‚¬ì´ì˜ ì‚°ì ë„ ê·¸ë˜í”„ íˆ¬ëª…ë„0.5
plt.scatter(y_test, y_pred_rf, alpha=0.5)
#x=yì„  r-- ë¹¨ê°„ì ì„ ìœ¼ë¡œ
#ì˜ˆì¸¡ê°’ì´ ì‹¤ì œê°’ê³¼ ì™„ì „íˆ ê°™ë‹¤ë©´ ì°íˆëŠ” ê¸°ì¤€ì„ 
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test    .max()], 'r--')
plt.xlabel("Actual Tg")
plt.ylabel("Predicted Tg")
plt.title("Random Forest: Actual vs Predicted Tg")
plt.grid(True)
plt.show()








#Feature ì¤‘ìš”ë„ ë¶„ì„
# ëª¨ë¸ì´ ê³„ì‚°í•œ íŠ¹ì„± ì¤‘ìš”ë„ ë°°ì—´
importances = rf_model.feature_importances_
feature_names = ['NR', 'SBR', 'BR']

sns.barplot(x=importances, y=feature_names)
plt.title("Feature Importance (Random Forest)")
plt.show()
#BRì´ ë†’ì€ê±¸ ë³´ë‹ˆ(0.5ì´ìƒ),BR ì¡°ì„±ì´ ìœ ë¦¬ì „ì´ì˜¨ë„ì— ì¤‘ìš”í•œ ì—­í™•ì„ í•¨





import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# 1. ë¬´ì‘ìœ„ ê³ ë¶„ì ì¡°ì„±(NR, SBR, BR)ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_compositions(n_samples=8000):
    compositions = []
    for _ in range(n_samples):
        nr = np.random.uniform(0.0, 1.0)                  # NR ë¹„ìœ¨ì„ 0~1 ì‚¬ì´ì—ì„œ ë¬´ì‘ìœ„ë¡œ ì„ íƒ
        sbr = np.random.uniform(0.0, 1.0 - nr)            # SBRì€ ì „ì²´ê°€ 1ì„ ë„˜ì§€ ì•Šê²Œ NRê³¼ í•©ì‚° ì œí•œ
        br = 1.0 - nr - sbr                               # BRì€ ë‚˜ë¨¸ì§€ë¡œ ê³„ì‚° â†’ NR+SBR+BR = 1
        compositions.append([round(nr, 3), round(sbr, 3), round(br, 3)])
    return np.array(compositions)


# 2. ì¡°ì„±ì— ë”°ë¼ Tg ë° ë°€ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (ë¬¸í—Œ Tg,density ê°’ì„ ì°¸ê³ í•˜ì—¬ ë°ì´í„° ë§Œë“¦ + ë…¸ì´ì¦ˆ)
def estimate_properties(nr, sbr, br):
    tg = nr * 243 + sbr * 234 + br * 210 + np.random.normal(0, 1)  # ë¬¸í—Œìƒì˜ ê°€ì¤‘ í‰ê·  + ì•½ê°„ì˜ ë…¸ì´ì¦ˆ
    density = nr * 0.94 + sbr * 0.96 + br * 0.93 + np.random.normal(0, 0.002)
    return round(tg, 2), round(density, 3)


n_samples = 8000
compositions = generate_compositions(n_samples)

data = []
for nr, sbr, br in compositions:
    tg, density = estimate_properties(nr, sbr, br)
    data.append({"NR": nr, "SBR": sbr, "BR": br, "Tg_K": tg, "Density": density})

df_2 = pd.DataFrame(data)

# 2. ì‹œê°í™”: BR ì¡°ì„±ì— ë”°ë¥¸ Tg
plt.figure(figsize=(8, 6))
sns.scatterplot(x="BR", y="Tg_K", data=df_2, alpha=0.3, label="Samples")
sns.regplot(x="BR", y="Tg_K", data=df_2, scatter=False, color='red', label="Trend Line")
plt.title("Tg vs BR Composition")
plt.xlabel("BR Composition")
plt.ylabel("Glass Transition Temperature (K)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()











import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# 1. BR ê°’ì„ 0.0ë¶€í„° 1.0ê¹Œì§€ 100ê°œë¡œ ë‚˜ëˆ ì„œ ìƒì„±
br_values = np.linspace(0, 1, 100)

# 2. NR, SBR ë¹„ìœ¨ ê³ ì • (ì˜ˆ: NR=0.3, SBR=0.3 â†’ BR=0.4 ~ 1.0 ì‚¬ì´ ê°€ëŠ¥)
#    BRì´ ëŠ˜ì–´ë‚˜ë©´ NR+SBRì€ ì¤„ì–´ë“¤ì–´ì•¼ í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” NR, SBRì„ 0ìœ¼ë¡œ í•˜ê³  BRë§Œ 0~1ë¡œ ì¡°ì ˆ (ë‹¨ì¼ ì˜í–¥ í™•ì¸)
nr_fixed = 0.0
sbr_fixed = 0.0

# 3. ì¡°ì„± ë°°ì—´ ìƒì„±
X_br_variation = pd.DataFrame({
    "NR": [nr_fixed] * len(br_values),
    "SBR": [sbr_fixed] * len(br_values),
    "BR": br_values
})

# 4. Tg ì˜ˆì¸¡
y_pred_tg = rf_model.predict(X_br_variation)

# 5. ì‹œê°í™”
plt.figure(figsize=(8, 6))
plt.plot(br_values, y_pred_tg, label="Predicted Tg", color='blue')
plt.xlabel("BR Composition")
plt.ylabel("Predicted Tg (K)")
sns.scatterplot(x=df["BR"], y=df["Tg_K"], alpha=0.3, label="Actual Data")
plt.title("ğŸ“ˆ Predicted Tg vs BR Composition (Random Forest)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

#ìœ ë¦¬ ì „ì´ ì˜¨ë„ì— ì˜í–¥ì„ ì£¼ëŠ” ê°’ì„ ì•Œì•„ë³´ê³  ì‹¤ì œë¡œ ì˜ˆì¸¡ í–ˆì„ë•Œ ë¹„ìŠ·í•˜ê²Œ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë‚¼ìˆ˜ ìˆì„ì§€ë¥¼ ë³´ì•˜ë‹¤
#ë‹¤ë¥¸ íŠ¹ì„±ë„ ì´ì™€ ê°™ì´ ë¶„ì„í•´ì„œ ì•Œì•„ ë‚´ë©´ ë ê²ƒ ê°™ìŒ